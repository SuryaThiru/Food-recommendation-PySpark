{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setups and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.15.2)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas) (2018.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "\u001b[31mpyspark 2.3.1 requires py4j==0.10.7, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.6/site-packages (0.15.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.6/site-packages (from textblob) (3.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.11.0)\n",
      "\u001b[31mpyspark 2.3.1 requires py4j==0.10.7, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting swifter\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/58/a519e2fcd8bf50ac02659fe9958d972a0c2698ed4c2172fdd1f82a4d64e5/swifter-0.251.tar.gz\n",
      "Requirement already satisfied: pandas>=0.23.0 in /opt/conda/lib/python3.6/site-packages (from swifter) (0.23.4)\n",
      "Collecting psutil (from swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/9a/1e93d41708f8ed2b564395edfa3389f0fd6d567597401c2e5e2775118d8b/psutil-5.4.7.tar.gz (420kB)\n",
      "\u001b[K    100% |████████████████████████████████| 430kB 1.6MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting dask[complete]>=0.19.0 (from swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/73/8ffed9140e343455427e92e6a32c354e9acdbef0a23d0e8d6c336d4947e5/dask-0.19.4-py2.py3-none-any.whl (674kB)\n",
      "\u001b[K    100% |████████████████████████████████| 675kB 1.8MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting tqdm (from swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/43/19c9fee28110cd47f73e6bc596394337fe9f3e5825b4de402bbf30b3beb5/tqdm-4.26.0-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 19.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23.0->swifter) (1.15.2)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23.0->swifter) (2018.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23.0->swifter) (2.7.3)\n",
      "Collecting toolz>=0.7.3; extra == \"complete\" (from dask[complete]>=0.19.0->swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/d0/a73c15bbeda3d2e7b381a36afb0d9cd770a9f4adc5d1532691013ba881db/toolz-0.9.0.tar.gz (45kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 18.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle>=0.2.1; extra == \"complete\" (from dask[complete]>=0.19.0->swifter)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/87/7b7ef3038b4783911e3fdecb5c566e3a817ce3e890e164fc174c088edb1e/cloudpickle-0.6.1-py2.py3-none-any.whl\n",
      "Collecting partd>=0.3.8; extra == \"complete\" (from dask[complete]>=0.19.0->swifter)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/bc/4dfd1e62e04a26d7ee56ade63af15e3249aeb3ed05d70ac590da2ca7c44d/partd-0.3.9-py2.py3-none-any.whl\n",
      "Collecting distributed>=1.22; extra == \"complete\" (from dask[complete]>=0.19.0->swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/13/090653f164bae030755660cea823fbece1f8a20cba15563544bc38719160/distributed-1.23.3-py2.py3-none-any.whl (497kB)\n",
      "\u001b[K    100% |████████████████████████████████| 501kB 20.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.23.0->swifter) (1.11.0)\n",
      "Collecting locket (from partd>=0.3.8; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/22/3c0f97614e0be8386542facb3a7dcfc2584f7b83608c02333bced641281c/locket-0.2.0.tar.gz\n",
      "Requirement already satisfied: tornado>=4.5.1 in /opt/conda/lib/python3.6/site-packages (from distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (5.1.1)\n",
      "Collecting msgpack (from distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/4e/dcf124fd97e5f5611123d6ad9f40ffd6eb979d1efdc1049e28a795672fcd/msgpack-0.5.6-cp36-cp36m-manylinux1_x86_64.whl (315kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 17.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting click>=6.6 (from distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 23.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tblib (from distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/82/1b9fba6e93629a8557f9784cd8f1ae063c8762c26446367a6764edd328ce/tblib-1.3.2-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 23.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers!=2.0.0,!=2.0.1 (from distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "  Downloading https://files.pythonhosted.org/packages/be/e3/a065de5fdd5849450a8a16a52a96c8db5f498f245e7eda06cc6725d04b80/sortedcontainers-2.0.5-py2.py3-none-any.whl\n",
      "Collecting zict>=0.1.3 (from distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/c9/eddd6c9a7ebd65fc799f9b87e56b45599a4e35d66e3da2722d7fc2a89f1f/zict-0.1.3-py2.py3-none-any.whl\n",
      "Collecting heapdict (from zict>=0.1.3->distributed>=1.22; extra == \"complete\"->dask[complete]>=0.19.0->swifter)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/ca/f5feba2f939c97629dbce52a17acc95a0d10256ef620334795379dda8ce6/HeapDict-1.0.0.tar.gz\n",
      "Building wheels for collected packages: swifter, psutil, toolz, locket, pyyaml, heapdict\n",
      "  Running setup.py bdist_wheel for swifter ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/36/9e/b5/989a490f6200d7377c2bc046cd27fa61f32f158bc8b8e258b7\n",
      "  Running setup.py bdist_wheel for psutil ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e2/9d/ea/1913d16f19bb927c32197308dec69cd8d10b61be8f7e265524\n",
      "  Running setup.py bdist_wheel for toolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f4/0c/f6/ce6b2d1aa459ee97cc3c0f82236302bd62d89c86c700219463\n",
      "  Running setup.py bdist_wheel for locket ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/26/1e/e8/4fa236ec931b1a0cdd61578e20d4934d7bf188858723b84698\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "  Running setup.py bdist_wheel for heapdict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/b9/42/344857b482c954f48bcff6db72d388e30bf2bee4ed14706faa\n",
      "Successfully built swifter psutil toolz locket pyyaml heapdict\n",
      "\u001b[31mpyspark 2.3.1 requires py4j==0.10.7, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "Installing collected packages: psutil, toolz, cloudpickle, locket, partd, msgpack, click, tblib, pyyaml, sortedcontainers, heapdict, zict, distributed, dask, tqdm, swifter\n",
      "Successfully installed click-7.0 cloudpickle-0.6.1 dask-0.19.4 distributed-1.23.3 heapdict-1.0.0 locket-0.2.0 msgpack-0.5.6 partd-0.3.9 psutil-5.4.7 pyyaml-3.13 sortedcontainers-2.0.5 swifter-0.251 tblib-1.3.2 toolz-0.9.0 tqdm-4.26.0 zict-0.1.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b2/05be9b6da9ae4a4c54f537be22e95833f722742a02b1e355fdc09363877c/scikit_learn-0.20.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.3MB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.15.2)\n",
      "Collecting scipy>=0.13.3 (from scikit-learn->sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 31.2MB 1.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "\u001b[31mpyspark 2.3.1 requires py4j==0.10.7, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "Installing collected packages: scipy, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.20.0 scipy-1.1.0 sklearn-0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into a dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('/user/recommend/Reviews.csv', header=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ProfileName: string (nullable = true)\n",
      " |-- HelpfulnessNumerator: string (nullable = true)\n",
      " |-- HelpfulnessDenominator: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+-----------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
      "| Id| ProductId|        UserId|ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n",
      "+---+----------+--------------+-----------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
      "|  1|B001E4KFG0|A3SGXH7AUHU8GW| delmartian|                   1|                     1|    5|1303862400|Good Quality Dog ...|I have bought sev...|\n",
      "|  2|B00813GRG4|A1D87F6ZCVE5NK|     dll pa|                   0|                     0|    1|1346976000|   Not as Advertised|\"Product arrived ...|\n",
      "|  4|B000UA0QIQ|A395BORC6FGVXV|       Karl|                   3|                     3|    2|1307923200|      Cough Medicine|If you are lookin...|\n",
      "+---+----------+--------------+-----------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'ProductId',\n",
       " 'UserId',\n",
       " 'ProfileName',\n",
       " 'HelpfulnessNumerator',\n",
       " 'HelpfulnessDenominator',\n",
       " 'Score',\n",
       " 'Time',\n",
       " 'Summary',\n",
       " 'Text']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- HelpfulnessNumerator: string (nullable = true)\n",
      " |-- HelpfulnessDenominator: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.drop('ProfileName', 'Time')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the user id since we will be building a item based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('UserId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+-----------+------+\n",
      "| Id|ProductId|Score|Helpfulness|Remark|\n",
      "+---+---------+-----+-----------+------+\n",
      "|  0|        0|    0|          0|     0|\n",
      "+---+---------+-----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col, isnull, lit\n",
    "\n",
    "data.select([count(when(isnull(c), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the helpfulness ratio from the cols and add it to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpfulness = data['HelpfulnessNumerator'] / (data['HelpfulnessNumerator'] + data['HelpfulnessDenominator'])\n",
    "data = data.withColumn('Helpfulness', helpfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Helpfulness: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.drop('HelpfulnessNumerator', 'HelpfulnessDenominator')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.na.fill(0.0, 'Helpfulness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the `summary` and `text` column to a new feature and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lit\n",
    "\n",
    "remark = concat(data['Summary'], lit(\" \"), data['Text'])\n",
    "data = data.withColumn('Remark', remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Helpfulness: double (nullable = false)\n",
      " |-- Remark: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.drop('Summary', 'Text')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              Remark|\n",
      "+--------------------+\n",
      "|Good Quality Dog ...|\n",
      "|Not as Advertised...|\n",
      "|Cough Medicine If...|\n",
      "|Great taffy Great...|\n",
      "|Nice Taffy I got ...|\n",
      "|Great!  Just as g...|\n",
      "|Wonderful, tasty ...|\n",
      "|Yay Barley Right ...|\n",
      "|Healthy Dog Food ...|\n",
      "|The Best Hot Sauc...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Remark').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `Remark` feature into its corresponding sentiment polarity. Due to the diversity of words and context observed in the column word vectors will be too sparse and may not give good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "\n",
    "def to_sentiment(text):\n",
    "    from textblob import TextBlob\n",
    "    sen = TextBlob(text).sentiment.polarity\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to pandas and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 503209/503209 [08:50<00:00, 948.54it/s] \n"
     ]
    }
   ],
   "source": [
    "import swifter\n",
    "\n",
    "remarks = data.toPandas()['Remark']\n",
    "remarks = remarks.swifter.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Remark</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Good Quality Dog Food I have bought several of...</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not as Advertised \"Product arrived labeled as ...</td>\n",
       "      <td>-0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Cough Medicine If you are looking for the secr...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Great taffy Great taffy at a great price.  The...</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nice Taffy I got a wild hair for taffy and ord...</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id   ProductId Score  Helpfulness  \\\n",
       "0  1  B001E4KFG0     5          0.5   \n",
       "1  2  B00813GRG4     1          0.0   \n",
       "2  4  B000UA0QIQ     2          0.5   \n",
       "3  5  B006K2ZZ7K     5          0.0   \n",
       "4  6  B006K2ZZ7K     4          0.0   \n",
       "\n",
       "                                              Remark  Sentiment  \n",
       "0  Good Quality Dog Food I have bought several of...   0.485714  \n",
       "1  Not as Advertised \"Product arrived labeled as ... -0.0333333  \n",
       "2  Cough Medicine If you are looking for the secr...   0.166667  \n",
       "3  Great taffy Great taffy at a great price.  The...   0.546667  \n",
       "4  Nice Taffy I got a wild hair for taffy and ord...   0.291667  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = data.toPandas()\n",
    "new['Sentiment'] = remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.drop(['Remark'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+-----------+--------------------+\n",
      "| Id| ProductId|Score|Helpfulness|           Sentiment|\n",
      "+---+----------+-----+-----------+--------------------+\n",
      "|  1|B001E4KFG0|    5|        0.5|  0.4857142857142857|\n",
      "|  2|B00813GRG4|    1|        0.0|-0.03333333333333...|\n",
      "|  4|B000UA0QIQ|    2|        0.5| 0.16666666666666666|\n",
      "+---+----------+-----+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = sqlContext.createDataFrame(new)\n",
    "new_data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the current state of dataframe as csv back to the hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.write.csv('/user/recommend/Reviews_new2.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+-----------------+-------------------+-------------------+\n",
      "|summary|                Id|           ProductId|            Score|        Helpfulness|          Sentiment|\n",
      "+-------+------------------+--------------------+-----------------+-------------------+-------------------+\n",
      "|  count|            503209|              503209|           503209|             503209|             503209|\n",
      "|   mean| 284524.4813169081| 6.642618498597183E9|4.215810925480268|0.20846667140794187|0.27674306063227166|\n",
      "| stddev|164106.34224156503|2.1005649557905338E9|1.294689191294415| 0.2346928634057244|  0.236348700194211|\n",
      "|    min|                 1|          0006641040|                1|                0.0|               -1.0|\n",
      "|    max|             99999|          B009WVB40S|                5|               0.75|                1.0|\n",
      "+-------+------------------+--------------------+-----------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+-----------+-------------------+\n",
      "|    Id| ProductId|Score|Helpfulness|          Sentiment|\n",
      "+------+----------+-----+-----------+-------------------+\n",
      "|285151|B001E5E3JY|    5|        0.5|0.13819444444444448|\n",
      "|285152|B001E5E3JY|    5|        0.5|0.35833333333333334|\n",
      "+------+----------+-----+-----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_new = spark.read.csv('/user/recommend/Reviews_new2.csv', header=True, mode=\"DROPMALFORMED\")\n",
    "data_new.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate unreliability factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "| ProductId|     Unreliability|\n",
      "+----------+------------------+\n",
      "|B001E5E35S|0.5773502691896258|\n",
      "|B0064KOSYE|               0.0|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "\n",
    "unreliability = data_new.groupBy('ProductId').agg(stddev('Score').alias('Unreliability'))\n",
    "colname = unreliability.columns[1]\n",
    "\n",
    "unreliability = unreliability.na.fill(0.0, colname)\n",
    "unreliability.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "product_rating = data_new.groupBy('ProductId').agg(avg('Score').alias('Score'))\n",
    "product_helpful = data_new.groupBy('ProductId').agg(avg('Helpfulness').alias('Helpfulness'))\n",
    "product_sentiment = data_new.groupBy('ProductId').agg(avg('Sentiment').alias('Sentiment'))\n",
    "product_rating_count = data_new.groupBy('ProductId').agg(count('Score').alias('Count'))\n",
    "\n",
    "products = data_new.select('Productid').distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the features into a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = products.join(product_rating_count, 'ProductId').join(product_rating, 'ProductId')\\\n",
    ".join(product_helpful, 'ProductId').join(product_sentiment, 'ProductId')\\\n",
    ".join(unreliability, 'ProductId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-------------------+--------------------+------------------+\n",
      "| Productid|Count|Score|        Helpfulness|           Sentiment|     Unreliability|\n",
      "+----------+-----+-----+-------------------+--------------------+------------------+\n",
      "|B001E5E35S|    4|  4.5|0.20833333333333331|  0.3258531746031746|0.5773502691896258|\n",
      "|B0064KOSYE|    1|  1.0|                0.0|-0.21388888888888888|               0.0|\n",
      "|B0001NBGHM|    8| 3.75|0.26805555555555555|  0.2815917936230436|1.8322507626258084|\n",
      "|B001BTJNNE|    1|  5.0|                0.0| 0.34920634920634924|               0.0|\n",
      "|B004KZF39O|    1|  5.0|                0.5| 0.42346938775510207|               0.0|\n",
      "+----------+-----+-----+-------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_model.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(values):\n",
    "    mn = values.min()\n",
    "    mx = values.max()\n",
    "    return 10.0 / (mx - mn) * (values - mx) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mins, maxs = [], []\n",
    "cols = data_model.columns[1:]\n",
    "\n",
    "for col in cols:\n",
    "    mn = data_model.agg({col: 'min'}).collect()[0][0]\n",
    "    mins.append(mn)\n",
    "    \n",
    "for col in cols:\n",
    "    mx = data_model.agg({col: 'max'}).collect()[0][0]\n",
    "    maxs.append(mx)\n",
    "\n",
    "mn, mx = min(mins), max(maxs) # get the min and max values of all the values in dataframe\n",
    "\n",
    "def normalize(values):\n",
    "    return 10.0 / (mx - mn) * (values - mx) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Count', 'Score', 'Helpfulness', 'Sentiment', 'Unreliability']\n",
      "+----------+----------+-----------+-----------+-----------+-------------+\n",
      "| Productid|     Count|      Score|Helpfulness|  Sentiment|Unreliability|\n",
      "+----------+----------+-----------+-----------+-----------+-------------+\n",
      "|B001E5E35S|0.05733945|  0.0630734|0.013857034|0.015204738|  0.018088879|\n",
      "|B0064KOSYE|0.02293578| 0.02293578| 0.01146789|0.009015036|   0.01146789|\n",
      "|B0001NBGHM|0.10321101|0.054472476|0.014541921|0.014697154|  0.032479938|\n",
      "|B001BTJNNE|0.02293578| 0.06880734| 0.01146789| 0.01547255|   0.01146789|\n",
      "|B004KZF39O|0.02293578| 0.06880734|0.017201835| 0.01632419|   0.01146789|\n",
      "+----------+----------+-----------+-----------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "udf_norm = udf(normalize, FloatType())\n",
    "\n",
    "columns = data_model.columns[1:]\n",
    "print(columns)\n",
    "\n",
    "\n",
    "\n",
    "# data_model.withColumn('norm_count', udf_norm(data_model['Count'])).show(3)\n",
    "for col in columns:\n",
    "    data_model = data_model.withColumn(col, udf_norm(data_model[col]))\n",
    "    \n",
    "data_model.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpointing the dataframe. I'm basically paranoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.write.csv('/user/recommend/Reviews_norm.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = spark.read.csv('/user/recommend/Reviews_norm.csv', header=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = data_model.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.set_index('Productid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Score</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Unreliability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Productid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00019MN28</th>\n",
       "      <td>0.02293578</td>\n",
       "      <td>0.06880734</td>\n",
       "      <td>0.01146789</td>\n",
       "      <td>0.01827695</td>\n",
       "      <td>0.01146789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0018CLVFM</th>\n",
       "      <td>0.03440367</td>\n",
       "      <td>0.06880734</td>\n",
       "      <td>0.01146789</td>\n",
       "      <td>0.012123198</td>\n",
       "      <td>0.01146789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0001B8VRW</th>\n",
       "      <td>0.02293578</td>\n",
       "      <td>0.05733945</td>\n",
       "      <td>0.017201835</td>\n",
       "      <td>0.01425521</td>\n",
       "      <td>0.01146789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002LSI1SW</th>\n",
       "      <td>0.2293578</td>\n",
       "      <td>0.064582326</td>\n",
       "      <td>0.014156534</td>\n",
       "      <td>0.014298305</td>\n",
       "      <td>0.024266867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B001UUVKQM</th>\n",
       "      <td>0.02293578</td>\n",
       "      <td>0.06880734</td>\n",
       "      <td>0.017201835</td>\n",
       "      <td>0.014393888</td>\n",
       "      <td>0.01146789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Count        Score  Helpfulness    Sentiment Unreliability\n",
       "Productid                                                                  \n",
       "B00019MN28  0.02293578   0.06880734   0.01146789   0.01827695    0.01146789\n",
       "B0018CLVFM  0.03440367   0.06880734   0.01146789  0.012123198    0.01146789\n",
       "B0001B8VRW  0.02293578   0.05733945  0.017201835   0.01425521    0.01146789\n",
       "B002LSI1SW   0.2293578  0.064582326  0.014156534  0.014298305   0.024266867\n",
       "B001UUVKQM  0.02293578   0.06880734  0.017201835  0.014393888    0.01146789"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [['0.02293578' '0.06880734' '0.01146789' '0.01827695' '0.01146789']\n",
      " ['0.03440367' '0.06880734' '0.01146789' '0.012123198' '0.01146789']\n",
      " ['0.02293578' '0.05733945' '0.017201835' '0.01425521' '0.01146789']\n",
      " ...\n",
      " ['0.02293578' '0.04587156' '0.01146789' '0.010841251' '0.01146789']\n",
      " ['0.06880734' '0.059633028' '0.01146789' '0.015051605' '0.031982277']\n",
      " ['0.02293578' '0.06880734' '0.01146789' '0.0163513' '0.01146789']]\n",
      "Labels:  ['B00019MN28' 'B0018CLVFM' 'B0001B8VRW' ... 'B007FSAN9S' 'B0049BUWH2'\n",
      " 'B003EMQDVG']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "data_points = data_model.values\n",
    "labels = data_model.index.values\n",
    "\n",
    "print('Data: ', data_points)\n",
    "print('Labels: ', labels)\n",
    "\n",
    "engine.fit(data_points, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Products: \n",
      "[Index(['B0098WV8F2', 'B000VK08OC', 'B004E4CCSQ', 'B000FMZO8G', 'B000FMZO90',\n",
      "       'B004U49QU2', 'B0012NUVN0', 'B0012V1G0Y', 'B0009YJ4CW', 'B0045XE32E',\n",
      "       'B005BRHVD6', 'B004YV80O4', 'B004E4EBMG', 'B004WTHCO2', 'B001LQCOIS',\n",
      "       'B001P3PR54', 'B0009F3POY', 'B0083T6HC0', 'B0001ES9FI', 'B000OQ2DL4'],\n",
      "      dtype='object', name='Productid')]\n"
     ]
    }
   ],
   "source": [
    "product_id = 'B0098WV8F2'\n",
    "product_data = data_model.loc[product_id].values\n",
    "\n",
    "recommended_products = engine.kneighbors(X=[product_data], n_neighbors=20, return_distance=False)\n",
    "\n",
    "products_list = []\n",
    "for prod in recommended_products:\n",
    "    products_list.append(data_model.iloc[prod].index)\n",
    "    \n",
    "print('Recommended Products: ')\n",
    "print(products_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}